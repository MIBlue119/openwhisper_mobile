{
  "transcriptionProviders": [
    {
      "id": "openai",
      "name": "OpenAI",
      "baseUrl": "https://api.openai.com/v1",
      "models": [
        {
          "id": "gpt-4o-mini-transcribe",
          "name": "GPT-4o Mini Transcribe",
          "description": "Fast and accurate transcription"
        },
        {
          "id": "gpt-4o-transcribe",
          "name": "GPT-4o Transcribe",
          "description": "Most accurate transcription"
        },
        {
          "id": "whisper-1",
          "name": "Whisper",
          "description": "Original Whisper model"
        }
      ]
    },
    {
      "id": "groq",
      "name": "Groq",
      "baseUrl": "https://api.groq.com/openai/v1",
      "models": [
        {
          "id": "whisper-large-v3-turbo",
          "name": "Whisper Large v3 Turbo",
          "description": "216x real-time speed"
        }
      ]
    },
    {
      "id": "mistral",
      "name": "Mistral",
      "baseUrl": "https://api.mistral.ai/v1",
      "models": [
        {
          "id": "voxtral-mini-latest",
          "name": "Voxtral Mini",
          "description": "Fast multilingual transcription"
        }
      ]
    }
  ],
  "cloudProviders": [
    {
      "id": "openai",
      "name": "OpenAI",
      "models": [
        {
          "id": "gpt-5.2",
          "name": "GPT-5.2",
          "description": "Latest flagship reasoning model"
        },
        {
          "id": "gpt-5-mini",
          "name": "GPT-5 Mini",
          "description": "Fast and cost-efficient"
        },
        {
          "id": "gpt-5-nano",
          "name": "GPT-5 Nano",
          "description": "Ultra-fast, low latency"
        },
        {
          "id": "gpt-4.1",
          "name": "GPT-4.1",
          "description": "Strong baseline, 1M context"
        },
        {
          "id": "gpt-4.1-mini",
          "name": "GPT-4.1 Mini",
          "description": "Smaller GPT-4.1 model"
        },
        {
          "id": "gpt-4.1-nano",
          "name": "GPT-4.1 Nano",
          "description": "Lowest latency GPT-4.1"
        }
      ]
    },
    {
      "id": "anthropic",
      "name": "Anthropic",
      "models": [
        {
          "id": "claude-sonnet-4-5",
          "name": "Claude Sonnet 4.5",
          "description": "Balanced performance"
        },
        {
          "id": "claude-haiku-4-5",
          "name": "Claude Haiku 4.5",
          "description": "Fast with near-frontier intelligence"
        },
        {
          "id": "claude-opus-4-5",
          "name": "Claude Opus 4.5",
          "description": "Most capable Claude model"
        }
      ]
    },
    {
      "id": "gemini",
      "name": "Google Gemini",
      "models": [
        {
          "id": "gemini-3-pro-preview",
          "name": "Gemini 3 Pro",
          "description": "Next-gen flagship model for complex reasoning"
        },
        {
          "id": "gemini-3-flash-preview",
          "name": "Gemini 3 Flash",
          "description": "Ultra-fast, high-capability next-gen model"
        },
        {
          "id": "gemini-2.5-flash-lite",
          "name": "Gemini 2.5 Flash Lite",
          "description": "Lowest latency and cost"
        }
      ]
    },
    {
      "id": "groq",
      "name": "Groq",
      "models": [
        {
          "id": "qwen/qwen3-32b",
          "name": "Qwen3 32B",
          "description": "Powerful reasoning model, 131K context",
          "disableThinking": true
        },
        {
          "id": "openai/gpt-oss-120b",
          "name": "GPT-OSS 120B",
          "description": "OpenAI's open-source flagship, 500 T/sec"
        },
        {
          "id": "openai/gpt-oss-20b",
          "name": "GPT-OSS 20B",
          "description": "Fast open-source model, 1000 T/sec"
        },
        {
          "id": "llama-3.3-70b-versatile",
          "name": "LLaMA 3.3 70B",
          "description": "Meta's versatile model, 280 T/sec"
        },
        {
          "id": "llama-3.1-8b-instant",
          "name": "LLaMA 3.1 8B",
          "description": "Ultra-fast 560 T/sec, 131K context"
        },
        {
          "id": "mixtral-8x7b-32768",
          "name": "Mixtral 8x7B",
          "description": "32K context, mixture of experts"
        },
        {
          "id": "gemma2-9b-it",
          "name": "Gemma 2 9B",
          "description": "Google's efficient model"
        }
      ]
    }
  ]
}
